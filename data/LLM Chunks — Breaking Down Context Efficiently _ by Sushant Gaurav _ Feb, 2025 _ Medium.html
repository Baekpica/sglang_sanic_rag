<!doctype html><html lang="en"><head><title data-rh="true">LLM Chunks — Breaking Down Context Efficiently | by Sushant Gaurav | Feb, 2025 | Medium</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2025-02-26T07:06:01.254Z"/><meta data-rh="true" name="title" content="LLM Chunks — Breaking Down Context Efficiently | by Sushant Gaurav | Feb, 2025 | Medium"/><meta data-rh="true" property="og:title" content="LLM Chunks — Breaking Down Context Efficiently"/><meta data-rh="true" property="al:android:url" content="medium://p/236dafe7b564"/><meta data-rh="true" property="al:ios:url" content="medium://p/236dafe7b564"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="So far, we have explored the evolution of Machine Learning (ML) and Natural Language Processing (NLP), leading up to modern Transformer-based models like GPT, BERT, and LLaMA. We have also dived into…"/><meta data-rh="true" property="og:description" content="Series Overview"/><meta data-rh="true" property="og:url" content="https://sushantgaurav57.medium.com/llm-chunks-breaking-down-context-efficiently-236dafe7b564"/><meta data-rh="true" property="al:web:url" content="https://sushantgaurav57.medium.com/llm-chunks-breaking-down-context-efficiently-236dafe7b564"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:1200/1*ln16vamAkf_WoiyAQjSL6w.png"/><meta data-rh="true" property="article:author" content="https://sushantgaurav57.medium.com"/><meta data-rh="true" name="author" content="Sushant Gaurav"/><meta data-rh="true" name="robots" content="index,noarchive,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" property="twitter:title" content="LLM Chunks — Breaking Down Context Efficiently"/><meta data-rh="true" name="twitter:site" content="@Medium"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/236dafe7b564"/><meta data-rh="true" property="twitter:description" content="Series Overview"/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:1200/1*ln16vamAkf_WoiyAQjSL6w.png"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="5 min read"/><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:304:304/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:240:240/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:152:152/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:120:120/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="mask-icon" href="https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png" color="#171717"/><link data-rh="true" rel="preconnect" href="https://glyph.medium.com" crossOrigin=""/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://sushantgaurav57.medium.com"/><link data-rh="true" rel="canonical" href="https://sushantgaurav57.medium.com/llm-chunks-breaking-down-context-efficiently-236dafe7b564"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/236dafe7b564"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F1*ln16vamAkf_WoiyAQjSL6w.png"],"url":"https:\u002F\u002Fsushantgaurav57.medium.com\u002Fllm-chunks-breaking-down-context-efficiently-236dafe7b564","dateCreated":"2025-02-26T07:06:01.254Z","datePublished":"2025-02-26T07:06:01.254Z","dateModified":"2025-02-26T08:29:07.531Z","headline":"LLM Chunks — Breaking Down Context Efficiently - Sushant Gaurav - Medium","name":"LLM Chunks — Breaking Down Context Efficiently - Sushant Gaurav - Medium","description":"So far, we have explored the evolution of Machine Learning (ML) and Natural Language Processing (NLP), leading up to modern Transformer-based models like GPT, BERT, and LLaMA. We have also dived into…","identifier":"236dafe7b564","author":{"@type":"Person","name":"Sushant Gaurav","url":"https:\u002F\u002Fsushantgaurav57.medium.com"},"creator":["Sushant Gaurav"],"publisher":{"@type":"Organization","name":"Medium","url":"https:\u002F\u002Fsushantgaurav57.medium.com\u002F","logo":{"@type":"ImageObject","width":272,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:544\u002F7*V1_7XP4snlmqrc_0Njontw.png"}},"mainEntityOfPage":"https:\u002F\u002Fsushantgaurav57.medium.com\u002Fllm-chunks-breaking-down-context-efficiently-236dafe7b564"}</script><style type="text/css" data-fela-rehydration="545" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}.grecaptcha-badge{visibility:hidden}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="545" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au{width:auto}.av path{fill:#242424}.aw{height:25px}.ax{margin-left:16px}.ay{border:none}.az{border-radius:20px}.ba{width:240px}.bb{background:#F9F9F9}.bc path{fill:#6B6B6B}.be{outline:none}.bf{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bg{font-size:14px}.bh{width:100%}.bi{padding:10px 20px 10px 0}.bj{background-color:transparent}.bk{color:#242424}.bl::placeholder{color:#6B6B6B}.bm{display:inline-block}.bn{margin-left:12px}.bo{margin-right:12px}.bp{border-radius:4px}.bq{margin-left:24px}.br{height:24px}.bx{background-color:#F9F9F9}.by{border-radius:50%}.bz{height:32px}.ca{width:32px}.cb{justify-content:center}.ch{max-width:680px}.ci{min-width:0}.cj{animation:k1 1.2s ease-in-out infinite}.ck{height:100vh}.cl{margin-bottom:16px}.cm{margin-top:48px}.cn{align-items:flex-start}.co{flex-direction:column}.cp{justify-content:space-between}.cq{margin-bottom:24px}.cw{width:80%}.cx{background-color:#F2F2F2}.dd{height:44px}.de{width:44px}.df{margin:auto 0}.dg{margin-bottom:4px}.dh{height:16px}.di{width:120px}.dj{width:80px}.dp{margin-bottom:8px}.dq{width:96%}.dr{width:98%}.ds{width:81%}.dt{margin-left:8px}.du{color:#6B6B6B}.dv{font-size:13px}.dw{height:100%}.ep{color:#FFFFFF}.eq{fill:#FFFFFF}.er{background:#1A8917}.es{border-color:#1A8917}.ew:disabled{cursor:inherit !important}.ex:disabled{opacity:0.3}.ey:disabled:hover{background:#1A8917}.ez:disabled:hover{border-color:#1A8917}.fa{border-radius:99em}.fb{border-width:1px}.fc{border-style:solid}.fd{box-sizing:border-box}.fe{text-decoration:none}.ff{text-align:center}.fi{margin-right:32px}.fj{position:relative}.fk{fill:#6B6B6B}.fn{background:transparent}.fo svg{margin-left:4px}.fp svg{fill:#6B6B6B}.fr{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fs{position:absolute}.fz{margin:0 24px}.gd{background:rgba(255, 255, 255, 1)}.ge{border:1px solid #F2F2F2}.gf{box-shadow:0 1px 4px #F2F2F2}.gg{max-height:100vh}.gh{overflow-y:auto}.gi{left:0}.gj{top:calc(100vh + 100px)}.gk{bottom:calc(100vh + 100px)}.gl{width:10px}.gm{pointer-events:none}.gn{word-break:break-word}.go{word-wrap:break-word}.gp:after{display:block}.gq:after{content:""}.gr:after{clear:both}.gs{line-height:1.23}.gt{letter-spacing:0}.gu{font-style:normal}.gv{font-weight:700}.ia{align-items:baseline}.ib{width:48px}.ic{height:48px}.id{border:2px solid rgba(255, 255, 255, 1)}.ie{z-index:0}.if{box-shadow:none}.ig{border:1px solid rgba(0, 0, 0, 0.05)}.ih{margin-bottom:2px}.ii{flex-wrap:nowrap}.ij{font-size:16px}.ik{line-height:24px}.im{margin:0 8px}.in{display:inline}.io{color:#1A8917}.ip{fill:#1A8917}.is{flex:0 0 auto}.iv{flex-wrap:wrap}.iw{padding-left:8px}.ix{padding-right:8px}.jy> *{flex-shrink:0}.jz{overflow-x:scroll}.ka::-webkit-scrollbar{display:none}.kb{scrollbar-width:none}.kc{-ms-overflow-style:none}.kd{width:74px}.ke{flex-direction:row}.kf{z-index:2}.kg{margin-right:4px}.kj{-webkit-user-select:none}.kk{border:0}.kl{fill:rgba(117, 117, 117, 1)}.ko{outline:0}.kp{user-select:none}.kq> svg{pointer-events:none}.kz{cursor:progress}.la{opacity:1}.lb{padding:4px 0}.le{margin-top:0px}.lf{width:16px}.lh{display:inline-flex}.ln{max-width:100%}.lo{padding:8px 2px}.lp svg{color:#6B6B6B}.mg{margin-left:auto}.mh{margin-right:auto}.mi{max-width:1308px}.mo{clear:both}.mq{cursor:zoom-in}.mr{z-index:auto}.mt{height:auto}.mu{line-height:1.12}.mv{letter-spacing:-0.022em}.mw{font-weight:600}.nr{margin-bottom:-0.28em}.ns{line-height:1.58}.nt{letter-spacing:-0.004em}.nu{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.op{margin-bottom:-0.46em}.oq{text-decoration:underline}.ow{list-style-type:decimal}.ox{margin-left:30px}.oy{padding-left:0px}.pe{margin-top:32px}.pf{margin-bottom:14px}.pg{padding-top:24px}.ph{padding-bottom:10px}.pi{background-color:#000000}.pj{height:3px}.pk{width:3px}.pl{margin-right:20px}.pr{list-style-type:disc}.ps{line-height:1.18}.qg{margin-bottom:-0.31em}.qh{max-width:426px}.qn{max-width:804px}.qo{max-width:550px}.qp{max-width:1062px}.qq{max-width:608px}.qr{max-width:764px}.qs{margin-bottom:26px}.qt{margin-top:6px}.qu{margin-top:8px}.qv{margin-right:8px}.qw{padding:8px 16px}.qx{border-radius:100px}.qy{transition:background 300ms ease}.ra{white-space:nowrap}.rb{border-top:none}.rc{margin-bottom:50px}.rd{height:52px}.re{max-height:52px}.rf{box-sizing:content-box}.rg{position:static}.rh{z-index:1}.rj{max-width:155px}.rp{margin-bottom:64px}.se{height:64px}.sf{width:64px}.sg{align-self:flex-end}.sh{color:rgba(255, 255, 255, 1)}.si{fill:rgba(255, 255, 255, 1)}.sj{background:rgba(25, 25, 25, 1)}.sk{border-color:rgba(25, 25, 25, 1)}.sn:disabled{opacity:0.1}.so:disabled:hover{background:rgba(25, 25, 25, 1)}.sp:disabled:hover{border-color:rgba(25, 25, 25, 1)}.sq{flex:1 1 auto}.sw{padding-right:4px}.sx{font-weight:500}.te{white-space:pre-wrap}.tf{margin-top:16px}.tg{margin-bottom:54px}.th{height:0px}.ti{gap:18px}.tj{fill:rgba(61, 61, 61, 1)}.tv{border-bottom:solid 1px #E5E5E5}.tw{margin-top:72px}.tx{padding:24px 0}.ty{margin-bottom:0px}.tz{margin-right:16px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.et:hover{background:#156D12}.eu:hover{border-color:#156D12}.ev:hover{cursor:pointer}.fl:hover{color:#242424}.fm:hover{fill:#242424}.fq:hover svg{fill:#242424}.ft:hover{background-color:rgba(0, 0, 0, 0.1)}.il:hover{text-decoration:underline}.iq:hover:not(:disabled){color:#156D12}.ir:hover:not(:disabled){fill:#156D12}.kn:hover{fill:rgba(8, 8, 8, 1)}.lc:hover{fill:#000000}.ld:hover p{color:#000000}.lg:hover{color:#000000}.lq:hover svg{color:#000000}.qz:hover{background-color:#F2F2F2}.sd:hover{background-color:none}.sl:hover{background:#000000}.sm:hover{border-color:#242424}.tk:hover{fill:rgba(25, 25, 25, 1)}.bd:focus-within path{fill:#242424}.km:focus{fill:rgba(8, 8, 8, 1)}.lr:focus svg{color:#000000}.ms:focus{transform:scale(1.01)}.kr:active{border-style:none}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bw{width:64px}.cg{margin:0 64px}.cv{height:48px}.dc{margin-bottom:52px}.do{margin-bottom:48px}.ef{font-size:14px}.eg{line-height:20px}.em{font-size:13px}.eo{padding:5px 12px}.fh{display:flex}.fy{margin-bottom:50px}.gc{max-width:680px}.hq{font-size:42px}.hr{margin-top:1.19em}.hs{margin-bottom:32px}.ht{line-height:52px}.hu{letter-spacing:-0.011em}.hz{align-items:center}.jk{border-top:solid 1px #F2F2F2}.jl{border-bottom:solid 1px #F2F2F2}.jm{margin:32px 0 0}.jn{padding:3px 8px}.jw> *{margin-right:24px}.jx> :last-child{margin-right:0}.ky{margin-top:0px}.lm{margin:0}.mn{margin-top:40px}.nn{font-size:24px}.no{margin-top:1.95em}.np{line-height:30px}.nq{letter-spacing:-0.016em}.ol{font-size:20px}.om{margin-top:0.94em}.on{line-height:32px}.oo{letter-spacing:-0.003em}.ov{margin-top:2.14em}.pd{margin-top:1.14em}.pq{margin-top:1.25em}.qd{margin-top:1.72em}.qe{line-height:24px}.qf{letter-spacing:0}.qm{margin-top:56px}.ro{display:inline-block}.rq{flex-direction:row}.rt{margin-bottom:0}.ru{margin-right:20px}.sr{max-width:500px}.tp{margin:40px 0 0}.tu{padding-top:72px}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.kx{margin-top:0px}.rn{display:inline-block}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.kw{margin-top:0px}.rm{display:inline-block}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.ku{margin-top:0px}.kv{margin-right:0px}.rl{display:inline-block}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dx{font-size:13px}.dy{line-height:20px}.eh{padding:0px 8px 1px}.fu{margin-bottom:2px}.gw{font-size:32px}.gx{margin-top:1.01em}.gy{margin-bottom:24px}.gz{line-height:38px}.ha{letter-spacing:-0.014em}.hv{align-items:flex-start}.it{flex-direction:column}.iy{margin:24px -24px 0}.iz{padding:0}.jo> *{margin-right:8px}.jp> :last-child{margin-right:24px}.kh{margin-left:0px}.ks{margin-top:0px}.kt{margin-right:0px}.li{margin:0}.ls{border:1px solid #F2F2F2}.lt{border-radius:99em}.lu{padding:0px 16px 0px 12px}.lv{height:38px}.lw{align-items:center}.ly svg{margin-right:8px}.mj{margin-top:32px}.mx{font-size:20px}.my{margin-top:1.2em}.mz{line-height:24px}.na{letter-spacing:0}.nv{font-size:18px}.nw{margin-top:0.67em}.nx{line-height:28px}.ny{letter-spacing:-0.003em}.or{margin-top:1.56em}.oz{margin-top:1.34em}.pm{margin-top:0.93em}.pt{font-size:16px}.pu{margin-top:1.23em}.qi{margin-top:40px}.rk{display:inline-block}.sb{margin-bottom:20px}.sc{margin-right:0}.sv{max-width:100%}.sy{font-size:24px}.sz{line-height:30px}.ta{letter-spacing:-0.016em}.tl{margin:32px 0 0}.tq{padding-top:48px}.lx:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ed{font-size:14px}.ee{line-height:20px}.ek{font-size:13px}.el{padding:5px 12px}.fg{display:flex}.fx{margin-bottom:50px}.gb{max-width:680px}.hl{font-size:42px}.hm{margin-top:1.19em}.hn{margin-bottom:32px}.ho{line-height:52px}.hp{letter-spacing:-0.011em}.hy{align-items:center}.jg{border-top:solid 1px #F2F2F2}.jh{border-bottom:solid 1px #F2F2F2}.ji{margin:32px 0 0}.jj{padding:3px 8px}.ju> *{margin-right:24px}.jv> :last-child{margin-right:0}.ll{margin:0}.mm{margin-top:40px}.nj{font-size:24px}.nk{margin-top:1.95em}.nl{line-height:30px}.nm{letter-spacing:-0.016em}.oh{font-size:20px}.oi{margin-top:0.94em}.oj{line-height:32px}.ok{letter-spacing:-0.003em}.ou{margin-top:2.14em}.pc{margin-top:1.14em}.pp{margin-top:1.25em}.qa{margin-top:1.72em}.qb{line-height:24px}.qc{letter-spacing:0}.ql{margin-top:56px}.rr{flex-direction:row}.rv{margin-bottom:0}.rw{margin-right:20px}.ss{max-width:500px}.to{margin:40px 0 0}.tt{padding-top:72px}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bu{width:64px}.ce{margin:0 48px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.eb{font-size:13px}.ec{line-height:20px}.ej{padding:0px 8px 1px}.fw{margin-bottom:50px}.ga{max-width:680px}.hg{font-size:42px}.hh{margin-top:1.19em}.hi{margin-bottom:32px}.hj{line-height:52px}.hk{letter-spacing:-0.011em}.hx{align-items:center}.jc{border-top:solid 1px #F2F2F2}.jd{border-bottom:solid 1px #F2F2F2}.je{margin:32px 0 0}.jf{padding:3px 8px}.js> *{margin-right:24px}.jt> :last-child{margin-right:0}.lk{margin:0}.ml{margin-top:40px}.nf{font-size:24px}.ng{margin-top:1.95em}.nh{line-height:30px}.ni{letter-spacing:-0.016em}.od{font-size:20px}.oe{margin-top:0.94em}.of{line-height:32px}.og{letter-spacing:-0.003em}.ot{margin-top:2.14em}.pb{margin-top:1.14em}.po{margin-top:1.25em}.px{margin-top:1.72em}.py{line-height:24px}.pz{letter-spacing:0}.qk{margin-top:56px}.rs{flex-direction:row}.rx{margin-bottom:0}.ry{margin-right:20px}.st{max-width:500px}.tn{margin:40px 0 0}.ts{padding-top:72px}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bt{width:24px}.cd{margin:0 24px}.cs{height:40px}.cz{margin-bottom:44px}.dl{margin-bottom:32px}.dz{font-size:13px}.ea{line-height:20px}.ei{padding:0px 8px 1px}.fv{margin-bottom:2px}.hb{font-size:32px}.hc{margin-top:1.01em}.hd{margin-bottom:24px}.he{line-height:38px}.hf{letter-spacing:-0.014em}.hw{align-items:flex-start}.iu{flex-direction:column}.ja{margin:24px 0 0}.jb{padding:0}.jq> *{margin-right:8px}.jr> :last-child{margin-right:8px}.ki{margin-left:0px}.lj{margin:0}.lz{border:1px solid #F2F2F2}.ma{border-radius:99em}.mb{padding:0px 16px 0px 12px}.mc{height:38px}.md{align-items:center}.mf svg{margin-right:8px}.mk{margin-top:32px}.nb{font-size:20px}.nc{margin-top:1.2em}.nd{line-height:24px}.ne{letter-spacing:0}.nz{font-size:18px}.oa{margin-top:0.67em}.ob{line-height:28px}.oc{letter-spacing:-0.003em}.os{margin-top:1.56em}.pa{margin-top:1.34em}.pn{margin-top:0.93em}.pv{font-size:16px}.pw{margin-top:1.23em}.qj{margin-top:40px}.rz{margin-bottom:20px}.sa{margin-right:0}.su{max-width:100%}.tb{font-size:24px}.tc{line-height:30px}.td{letter-spacing:-0.016em}.tm{margin:32px 0 0}.tr{padding-top:48px}.me:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="print">.ri{display:none}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.mp{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="l m n o c"><div class="p q r s t u v w x i d y z"><a class="du ag dv bf ak b am an ao ap aq ar as at s u w i d q dw z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F236dafe7b564&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderUser&amp;source=---top_nav_layout_nav-----------------------------------------" rel="noopener follow">Open in app<svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="none" viewBox="0 0 10 10" class="dt"><path fill="currentColor" d="M.985 8.485a.375.375 0 1 0 .53.53zM8.75 1.25h.375A.375.375 0 0 0 8.75.875zM8.375 6.5a.375.375 0 1 0 .75 0zM3.5.875a.375.375 0 1 0 0 .75zm-1.985 8.14 7.5-7.5-.53-.53-7.5 7.5zm6.86-7.765V6.5h.75V1.25zM3.5 1.625h5.25v-.75H3.5z"></path></svg></a><div class="ab q"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><button class="bf b dx dy eh dz ea ei eb ec ej ek ee el em eg eo ep eq er es et eu ev ew ex ey ez fa fb fc fd bm fe ff" data-testid="headerSignUpButton">Sign up</button></span></p><div class="ax l"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fsushantgaurav57.medium.com%2Fllm-chunks-breaking-down-context-efficiently-236dafe7b564&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" data-testid="headerMediumLogo" href="https://medium.com/?source=---top_nav_layout_nav-----------------------------------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="719" height="160" fill="none" viewBox="0 0 719 160" class="au av aw"><path fill="#242424" d="m174.104 9.734.215-.047V8.02H130.39L89.6 103.89 48.81 8.021H1.472v1.666l.212.047c8.018 1.81 12.09 4.509 12.09 14.242V137.93c0 9.734-4.087 12.433-12.106 14.243l-.212.047v1.671h32.118v-1.665l-.213-.048c-8.018-1.809-12.089-4.509-12.089-14.242V30.586l52.399 123.305h2.972l53.925-126.743V140.75c-.687 7.688-4.721 10.062-11.982 11.701l-.215.05v1.652h55.948v-1.652l-.215-.05c-7.269-1.639-11.4-4.013-12.087-11.701l-.037-116.774h.037c0-9.733 4.071-12.432 12.087-14.242m25.555 75.488c.915-20.474 8.268-35.252 20.606-35.507 3.806.063 6.998 1.312 9.479 3.714 5.272 5.118 7.751 15.812 7.368 31.793zm-.553 5.77h65.573v-.275c-.186-15.656-4.721-27.834-13.466-36.196-7.559-7.227-18.751-11.203-30.507-11.203h-.263c-6.101 0-13.584 1.48-18.909 4.16-6.061 2.807-11.407 7.003-15.855 12.511-7.161 8.874-11.499 20.866-12.554 34.343q-.05.606-.092 1.212a50 50 0 0 0-.065 1.151 85.807 85.807 0 0 0-.094 5.689c.71 30.524 17.198 54.917 46.483 54.917 25.705 0 40.675-18.791 44.407-44.013l-1.886-.664c-6.557 13.556-18.334 21.771-31.738 20.769-18.297-1.369-32.314-19.922-31.042-42.395m139.722 41.359c-2.151 5.101-6.639 7.908-12.653 7.908s-11.513-4.129-15.418-11.63c-4.197-8.053-6.405-19.436-6.405-32.92 0-28.067 8.729-46.22 22.24-46.22 5.657 0 10.111 2.807 12.236 7.704zm43.499 20.008c-8.019-1.897-12.089-4.722-12.089-14.951V1.309l-48.716 14.353v1.757l.299-.024c6.72-.543 11.278.386 13.925 2.83 2.072 1.915 3.082 4.853 3.082 8.987v18.66c-4.803-3.067-10.516-4.56-17.448-4.56-14.059 0-26.909 5.92-36.176 16.672-9.66 11.205-14.767 26.518-14.767 44.278-.003 31.72 15.612 53.039 38.851 53.039 13.595 0 24.533-7.449 29.54-20.013v16.865h43.711v-1.746zM424.1 19.819c0-9.904-7.468-17.374-17.375-17.374-9.859 0-17.573 7.632-17.573 17.374s7.721 17.374 17.573 17.374c9.907 0 17.375-7.47 17.375-17.374m11.499 132.546c-8.019-1.897-12.089-4.722-12.089-14.951h-.035V43.635l-43.714 12.551v1.705l.263.024c9.458.842 12.047 4.1 12.047 15.152v81.086h43.751v-1.746zm112.013 0c-8.018-1.897-12.089-4.722-12.089-14.951V43.635l-41.621 12.137v1.71l.246.026c7.733.813 9.967 4.257 9.967 15.36v59.279c-2.578 5.102-7.415 8.131-13.274 8.336-9.503 0-14.736-6.419-14.736-18.073V43.638l-43.714 12.55v1.703l.262.024c9.459.84 12.05 4.097 12.05 15.152v50.17a56.3 56.3 0 0 0 .91 10.444l.787 3.423c3.701 13.262 13.398 20.197 28.59 20.197 12.868 0 24.147-7.966 29.115-20.43v17.311h43.714v-1.747zm169.818 1.788v-1.749l-.213-.05c-8.7-2.006-12.089-5.789-12.089-13.49v-63.79c0-19.89-11.171-31.761-29.883-31.761-13.64 0-25.141 7.882-29.569 20.16-3.517-13.01-13.639-20.16-28.606-20.16-13.146 0-23.449 6.938-27.869 18.657V43.643L545.487 55.68v1.715l.263.024c9.345.829 12.047 4.181 12.047 14.95v81.784h40.787v-1.746l-.215-.053c-6.941-1.631-9.181-4.606-9.181-12.239V66.998c1.836-4.289 5.537-9.37 12.853-9.37 9.086 0 13.692 6.296 13.692 18.697v77.828h40.797v-1.746l-.215-.053c-6.94-1.631-9.18-4.606-9.18-12.239V75.066a42 42 0 0 0-.578-7.26c1.947-4.661 5.86-10.177 13.475-10.177 9.214 0 13.691 6.114 13.691 18.696v77.828z"></path></svg></a><div class="ax h"><div class="ab ay az ba bb q bc bd"><div class="bm" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bn bo ab"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ay be bf bg z bh bi bj bk bl" placeholder="Search" value=""/></div></div></div><div class="h k w fg fh"><div class="fi ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerWriteButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------" rel="noopener follow"><div class="bf b bg z du fj fk ab q fl fm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Write"><path fill="currentColor" d="M14 4a.5.5 0 0 0 0-1zm7 6a.5.5 0 0 0-1 0zm-7-7H4v1h10zM3 4v16h1V4zm1 17h16v-1H4zm17-1V10h-1v10zm-1 1a1 1 0 0 0 1-1h-1zM3 20a1 1 0 0 0 1 1v-1zM4 3a1 1 0 0 0-1 1h1z"></path><path stroke="currentColor" d="m17.5 4.5-8.458 8.458a.25.25 0 0 0-.06.098l-.824 2.47a.25.25 0 0 0 .316.316l2.47-.823a.25.25 0 0 0 .098-.06L19.5 6.5m-2-2 2.323-2.323a.25.25 0 0 1 .354 0l1.646 1.646a.25.25 0 0 1 0 .354L19.5 6.5m-2-2 2 2"></path></svg><div class="dt l">Write</div></div></a></span></div></div><div class="k j i d"><div class="fi ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSearchButton" href="https://medium.com/search?source=---top_nav_layout_nav-----------------------------------------" rel="noopener follow"><div class="bf b bg z du fj fk ab q fl fm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Search"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div></a></div></div><div class="fi h k j"><div class="ab q"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><button class="bf b dx dy eh dz ea ei eb ec ej ek ee el em eg eo ep eq er es et eu ev ew ex ey ez fa fb fc fd bm fe ff" data-testid="headerSignUpButton">Sign up</button></span></p><div class="ax l"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fsushantgaurav57.medium.com%2Fllm-chunks-breaking-down-context-efficiently-236dafe7b564&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="ay fn am ab q ao fo fp fq" aria-label="user options menu" data-testid="headerUserIcon"><div class="l fj"><img alt="" class="l fd by bz ca cx" src="https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"/><div class="fr by l bz ca fs n ay ft"></div></div></button></div></div></div><div class="l"><div class="fu fv fw fx fy l"><div class="ab cb"><div class="ci bh fz ga gb gc"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="fs gi gj gk gl gm"></div><div class="gn go gp gq gr"><div class="ab cb"><div class="ci bh fz ga gb gc"><div><h1 id="d924" class="pw-post-title gs gt gu bf gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp hq hr hs ht hu bk" data-testid="storyTitle">LLM Chunks — Breaking Down Context Efficiently</h1><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hv hw hx hy hz ab"><div><div class="ab ia"><div><div class="bm" aria-hidden="false"><a rel="noopener follow" href="/?source=post_page---byline--236dafe7b564---------------------------------------"><div class="l ib ic by id ie"><div class="l fj"><img alt="Sushant Gaurav" class="l fd by dd de cx" src="https://miro.medium.com/v2/resize:fill:88:88/1*zgHy2nSuAUuqTwQyuBS_FA.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"/><div class="if by l dd de fs n ig ft"></div></div></div></a></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="ih ab q"><div class="ab q ii"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ij ik bk"><a class="af ag ah ai aj ak al am an ao ap aq ar il" data-testid="authorName" rel="noopener follow" href="/?source=post_page---byline--236dafe7b564---------------------------------------">Sushant Gaurav</a></p></div></div></div><span class="im in" aria-hidden="true"><span class="bf b bg z du">·</span></span><p class="bf b ij ik du"><span><a class="io ip ah ai aj ak al am an ao ap aq ar ex iq ir" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F41ed97b9bd38&amp;operation=register&amp;redirect=https%3A%2F%2Fsushantgaurav57.medium.com%2Fllm-chunks-breaking-down-context-efficiently-236dafe7b564&amp;user=Sushant+Gaurav&amp;userId=41ed97b9bd38&amp;source=post_page-41ed97b9bd38--byline--236dafe7b564---------------------post_header------------------" rel="noopener follow">Follow</a></span></p></div></div></span></div></div><div class="l is"><span class="bf b bg z du"><div class="ab cn it iu iv"><span class="bf b bg z du"><div class="ab ae"><span data-testid="storyReadTime">5 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z du">·</span></span></div><span data-testid="storyPublishDate">Feb 26, 2025</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w fg fh q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon fj kg kh ki kj"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F236dafe7b564&amp;operation=register&amp;redirect=https%3A%2F%2Fsushantgaurav57.medium.com%2Fllm-chunks-breaking-down-context-efficiently-236dafe7b564&amp;user=Sushant+Gaurav&amp;userId=41ed97b9bd38&amp;source=---header_actions--236dafe7b564---------------------clap_footer------------------" rel="noopener follow"><div><div class="bm" aria-hidden="false"><div class="kk ao kl km kn ko am kp kq kr kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l ks kt ku kv kw kx ky"><p class="bf b dv z du"><span class="kz">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk la lb ab q fk lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"></div><div class="h k"><div><div class="bm" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F236dafe7b564&amp;operation=register&amp;redirect=https%3A%2F%2Fsushantgaurav57.medium.com%2Fllm-chunks-breaking-down-context-efficiently-236dafe7b564&amp;source=---header_actions--236dafe7b564---------------------bookmark_footer------------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du lg" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="fd lh cn"><div class="l ae"><div class="ab cb"><div class="li lj lk ll lm ln ci bh"><div class="ab"><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af fk ah ai aj ak al lo an ao ap ex lp lq ld lr ls lt lu lv s lw lx ly lz ma mb mc u md me mf"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"></path></svg><div class="j i d"><p class="bf b bg z du">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af fk ah ai aj ak al lo an ao ap ex lp lq ld lr ls lt lu lv s lw lx ly lz ma mb mc u md me mf"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg><div class="j i d"><p class="bf b bg z du">Share</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mj mk ml mm mn mo mg mh paragraph-image"><div role="button" tabindex="0" class="mp mq fj mr bh ms"><div class="mg mh mi"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ln16vamAkf_WoiyAQjSL6w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ln16vamAkf_WoiyAQjSL6w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ln16vamAkf_WoiyAQjSL6w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ln16vamAkf_WoiyAQjSL6w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ln16vamAkf_WoiyAQjSL6w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ln16vamAkf_WoiyAQjSL6w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ln16vamAkf_WoiyAQjSL6w.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*ln16vamAkf_WoiyAQjSL6w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ln16vamAkf_WoiyAQjSL6w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ln16vamAkf_WoiyAQjSL6w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ln16vamAkf_WoiyAQjSL6w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ln16vamAkf_WoiyAQjSL6w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ln16vamAkf_WoiyAQjSL6w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*ln16vamAkf_WoiyAQjSL6w.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bh ln mt c" width="700" height="398" loading="eager" role="presentation"/></picture></div></div></figure><h1 id="9d94" class="mu mv gu bf mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr bk">Series Overview</h1><p id="1a63" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">So far, we have explored the evolution of <a class="af oq" href="https://medium.com/p/4a64a679011b" rel="noopener"><strong class="nu gv">Machine Learning (ML) and Natural Language Processing (NLP)</strong>,</a> leading up to modern <strong class="nu gv">Transformer-based models</strong> like <strong class="nu gv">GPT, BERT, and LLaMA</strong>. We have also dived into <a class="af oq" href="https://medium.com/p/ea45fe63d89a" rel="noopener"><strong class="nu gv">Vector Search, Embeddings, and Retrieval-Augmented Generation (RAG)</strong></a> systems, understanding how they enhance <strong class="nu gv">Large Language Models (LLMs)</strong>. Additionally, we have simplified <a class="af oq" href="https://medium.com/p/18b1ce9e1a4b" rel="noopener"><strong class="nu gv">Vector Databases</strong></a>, explaining their fundamentals and real-world applications. Lastly, we have covered <a class="af oq" href="https://medium.com/p/1e80585402e3" rel="noopener"><strong class="nu gv">LangChain</strong></a>, its role in orchestrating LLM applications, and its practical implementations.</p><p id="afaf" class="pw-post-body-paragraph ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op gn bk">Building on this foundation, we now move forward with two key aspects of LLMs:</p><ol class=""><li id="cc3c" class="ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op ow ox oy bk"><strong class="nu gv">How chunking works in LLMs and its impact on cost and efficiency</strong></li><li id="aa39" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op ow ox oy bk"><strong class="nu gv">The broader impact of LLMs on ML, AI, and various industries</strong></li></ol></div></div></div><div class="ab cb pe pf pg ph" role="separator"><span class="pi by bm pj pk pl"></span><span class="pi by bm pj pk pl"></span><span class="pi by bm pj pk"></span></div><div class="gn go gp gq gr"><div class="ab cb"><div class="ci bh fz ga gb gc"><h1 id="fbbf" class="mu mv gu bf mw mx pm mz na nb pn nd ne nf po nh ni nj pp nl nm nn pq np nq nr bk">LLM Chunks — Breaking Down Context Efficiently</h1><p id="8bac" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">To effectively process long documents, LLMs <strong class="nu gv">break text into chunks</strong> before passing it as input. Choosing the right chunking method is critical because it affects <strong class="nu gv">context retention, accuracy, latency, and cost</strong>. In this article, we explore different <strong class="nu gv">chunking strategies</strong>, their trade-offs, and possible alternatives to improve efficiency.</p><h1 id="f9c9" class="mu mv gu bf mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr bk">What is Chunking in LLMs?</h1><p id="9cd1" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">Chunking in the context of LLMs refers to the <strong class="nu gv">process of dividing large text documents into smaller, manageable segments (chunks)</strong> before feeding them into the model. Since LLMs have a <strong class="nu gv">fixed context window</strong>, they cannot process infinite-length documents directly.</p><h1 id="137b" class="mu mv gu bf mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr bk">Why LLMs Need Chunking?</h1><p id="413f" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">LLMs like <strong class="nu gv">GPT-4</strong> and <strong class="nu gv">BERT</strong> have token limits (e.g., GPT-4’s context window is 8K-32K tokens). If a document exceeds this limit, it must be split into smaller sections. Chunking ensures that:</p><ul class=""><li id="6600" class="ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op pr ox oy bk"><strong class="nu gv">LLMs don’t miss critical information</strong> when handling large documents.</li><li id="e351" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Queries retrieve relevant sections efficiently</strong> instead of processing an entire dataset.</li><li id="afe7" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Costs are optimized</strong> by reducing unnecessary token usage.</li></ul><h1 id="1950" class="mu mv gu bf mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr bk">Real-World Use Cases Where Chunking is Essential</h1><ul class=""><li id="4d4e" class="ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op pr ox oy bk"><strong class="nu gv">Legal Document Analysis</strong>: Long contracts are split into sections for summarization.</li><li id="00b5" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Customer Support AI</strong>: Splitting FAQ databases into smaller knowledge chunks.</li><li id="eeeb" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Academic Research</strong>: Processing multi-page research papers efficiently.</li><li id="2deb" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Medical Records Analysis</strong>: Breaking down patient history for diagnostics.</li></ul><h1 id="086e" class="mu mv gu bf mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr bk">Common Chunking Methods</h1><h2 id="f1b6" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">1. Stuffing Method</h2><p id="d86b" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">In this method, all text is stuffed into a single chunk until the model’s token limit is reached. While simple, it has downsides:</p><ul class=""><li id="8adf" class="ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op pr ox oy bk"><strong class="nu gv">Pros:</strong> Low latency, easy to implement.</li><li id="733b" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Cons:</strong> Risk of losing information from truncated sections.</li></ul><figure class="qi qj qk ql qm mo mg mh paragraph-image"><div class="mg mh qh"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*zfNJBtPFAhab0Xs9J7GAmQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*zfNJBtPFAhab0Xs9J7GAmQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*zfNJBtPFAhab0Xs9J7GAmQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*zfNJBtPFAhab0Xs9J7GAmQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*zfNJBtPFAhab0Xs9J7GAmQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*zfNJBtPFAhab0Xs9J7GAmQ.png 1100w, https://miro.medium.com/v2/resize:fit:852/format:webp/1*zfNJBtPFAhab0Xs9J7GAmQ.png 852w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 426px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*zfNJBtPFAhab0Xs9J7GAmQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*zfNJBtPFAhab0Xs9J7GAmQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*zfNJBtPFAhab0Xs9J7GAmQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*zfNJBtPFAhab0Xs9J7GAmQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*zfNJBtPFAhab0Xs9J7GAmQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*zfNJBtPFAhab0Xs9J7GAmQ.png 1100w, https://miro.medium.com/v2/resize:fit:852/1*zfNJBtPFAhab0Xs9J7GAmQ.png 852w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 426px"/><img alt="" class="bh ln mt c" width="426" height="690" loading="lazy" role="presentation"/></picture></div></figure><h2 id="60e1" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">2. Map-Reduce Method</h2><p id="fe63" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">This method <strong class="nu gv">splits the document into multiple chunks</strong>, processes each one separately, and then combines results.</p><ul class=""><li id="b1fd" class="ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op pr ox oy bk"><strong class="nu gv">Pros:</strong> Scales well for large texts.</li><li id="fe30" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Cons:</strong> The combined result may lose coherence.</li></ul><figure class="qi qj qk ql qm mo mg mh paragraph-image"><div role="button" tabindex="0" class="mp mq fj mr bh ms"><div class="mg mh qn"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*N9ema5QK88Um2W2HBiBihA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*N9ema5QK88Um2W2HBiBihA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*N9ema5QK88Um2W2HBiBihA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*N9ema5QK88Um2W2HBiBihA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*N9ema5QK88Um2W2HBiBihA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*N9ema5QK88Um2W2HBiBihA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N9ema5QK88Um2W2HBiBihA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*N9ema5QK88Um2W2HBiBihA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*N9ema5QK88Um2W2HBiBihA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*N9ema5QK88Um2W2HBiBihA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*N9ema5QK88Um2W2HBiBihA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*N9ema5QK88Um2W2HBiBihA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*N9ema5QK88Um2W2HBiBihA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*N9ema5QK88Um2W2HBiBihA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bh ln mt c" width="700" height="624" loading="lazy" role="presentation"/></picture></div></div></figure><h2 id="abf3" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">3. Recursive Summary Method</h2><p id="abdc" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">This method involves <strong class="nu gv">summarizing individual chunks first</strong>, and then summarizing those summaries, ensuring context retention.</p><ul class=""><li id="4034" class="ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op pr ox oy bk"><strong class="nu gv">Pros:</strong> Retains more relevant context.</li><li id="ec20" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Cons:</strong> Requires multiple processing passes, increasing cost.</li></ul><h2 id="c947" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">4. Embedding-Based Chunking</h2><p id="2986" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">Instead of breaking text at arbitrary points, this method uses <strong class="nu gv">semantic similarity</strong> to keep related information together. This is useful in <strong class="nu gv">vector databases and RAG</strong>.</p><ul class=""><li id="0231" class="ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op pr ox oy bk"><strong class="nu gv">Pros:</strong> Ensures chunks retain full meaning.</li><li id="59d2" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Cons:</strong> Requires extra computation to determine chunk boundaries.</li></ul><figure class="qi qj qk ql qm mo mg mh paragraph-image"><div class="mg mh qo"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*UaCOkXK227_6V_kC3Tl-QQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*UaCOkXK227_6V_kC3Tl-QQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*UaCOkXK227_6V_kC3Tl-QQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*UaCOkXK227_6V_kC3Tl-QQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*UaCOkXK227_6V_kC3Tl-QQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*UaCOkXK227_6V_kC3Tl-QQ.png 1100w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*UaCOkXK227_6V_kC3Tl-QQ.png 1100w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 550px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*UaCOkXK227_6V_kC3Tl-QQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*UaCOkXK227_6V_kC3Tl-QQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*UaCOkXK227_6V_kC3Tl-QQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*UaCOkXK227_6V_kC3Tl-QQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*UaCOkXK227_6V_kC3Tl-QQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*UaCOkXK227_6V_kC3Tl-QQ.png 1100w, https://miro.medium.com/v2/resize:fit:1100/1*UaCOkXK227_6V_kC3Tl-QQ.png 1100w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 550px"/><img alt="" class="bh ln mt c" width="550" height="716" loading="lazy" role="presentation"/></picture></div></figure><h1 id="bd47" class="mu mv gu bf mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr bk">The Cost and Performance Trade-offs of Chunking</h1><h2 id="231b" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">Impact on API Call Costs</h2><p id="f712" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">Chunking affects the cost of <strong class="nu gv">LLM API calls</strong>, as providers charge based on <strong class="nu gv">token usage</strong>. Choosing the right chunking method can significantly optimize expenses.</p><p id="e572" class="pw-post-body-paragraph ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op gn bk">Chunking Method Token Usage Accuracy Cost Stuffing High Moderate Expensive Map-Reduce Medium High Moderate Recursive Summary Low High Expensive Embedding-Based Medium Very High Moderate</p><h2 id="9cdc" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">Accuracy vs. Speed vs. Computational Expense</h2><ul class=""><li id="ff59" class="ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op pr ox oy bk"><strong class="nu gv">More chunks = Better retrieval accuracy, but higher cost.</strong></li><li id="4745" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Fewer chunks = Lower cost, but higher risk of missing context.</strong></li></ul><h2 id="759e" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">Problems with Excessive Chunking</h2><p id="c31b" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">Too many small chunks can cause:</p><ul class=""><li id="ae90" class="ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op pr ox oy bk"><strong class="nu gv">Loss of coherence</strong> (context gets fragmented across multiple chunks).</li><li id="8690" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Higher processing costs</strong> due to increased API calls.</li></ul><figure class="qi qj qk ql qm mo mg mh paragraph-image"><div role="button" tabindex="0" class="mp mq fj mr bh ms"><div class="mg mh qp"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*AjYFxDpmjudrC1AwGDjo2w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*AjYFxDpmjudrC1AwGDjo2w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*AjYFxDpmjudrC1AwGDjo2w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*AjYFxDpmjudrC1AwGDjo2w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*AjYFxDpmjudrC1AwGDjo2w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*AjYFxDpmjudrC1AwGDjo2w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AjYFxDpmjudrC1AwGDjo2w.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*AjYFxDpmjudrC1AwGDjo2w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*AjYFxDpmjudrC1AwGDjo2w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*AjYFxDpmjudrC1AwGDjo2w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*AjYFxDpmjudrC1AwGDjo2w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*AjYFxDpmjudrC1AwGDjo2w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*AjYFxDpmjudrC1AwGDjo2w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*AjYFxDpmjudrC1AwGDjo2w.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bh ln mt c" width="700" height="114" loading="lazy" role="presentation"/></picture></div></div></figure><h1 id="5feb" class="mu mv gu bf mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr bk">Is There a Better Alternative to Chunking?</h1><p id="c666" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">While chunking is a practical way to handle LLM token limits, alternative methods aim to <strong class="nu gv">reduce chunking overhead</strong> while improving accuracy and efficiency. Some promising alternatives include:</p><h2 id="82bb" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">1. Adaptive Retrieval Techniques</h2><p id="f8b1" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">Instead of blindly chunking text, <strong class="nu gv">adaptive retrieval</strong> dynamically retrieves the most relevant sections based on the query. This is particularly useful in <strong class="nu gv">Retrieval-Augmented Generation (RAG) systems</strong>.</p><h2 id="60eb" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk"><strong class="al">How Adaptive Retrieval Works:</strong></h2><ol class=""><li id="41c7" class="ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op ow ox oy bk">Convert the document into <strong class="nu gv">vector embeddings</strong>.</li><li id="7600" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op ow ox oy bk">Store embeddings in a <strong class="nu gv">vector database</strong>.</li><li id="bf5d" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op ow ox oy bk">Retrieve the most relevant passages based on <strong class="nu gv">semantic similarity</strong> instead of fixed chunk sizes.</li></ol><p id="6ad0" class="pw-post-body-paragraph ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op gn bk"><strong class="nu gv">Example Workflow:</strong></p><figure class="qi qj qk ql qm mo mg mh paragraph-image"><div class="mg mh qq"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*poDsykkLGaD8X6BJANHpWA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*poDsykkLGaD8X6BJANHpWA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*poDsykkLGaD8X6BJANHpWA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*poDsykkLGaD8X6BJANHpWA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*poDsykkLGaD8X6BJANHpWA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*poDsykkLGaD8X6BJANHpWA.png 1100w, https://miro.medium.com/v2/resize:fit:1216/format:webp/1*poDsykkLGaD8X6BJANHpWA.png 1216w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 608px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*poDsykkLGaD8X6BJANHpWA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*poDsykkLGaD8X6BJANHpWA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*poDsykkLGaD8X6BJANHpWA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*poDsykkLGaD8X6BJANHpWA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*poDsykkLGaD8X6BJANHpWA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*poDsykkLGaD8X6BJANHpWA.png 1100w, https://miro.medium.com/v2/resize:fit:1216/1*poDsykkLGaD8X6BJANHpWA.png 1216w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 608px"/><img alt="" class="bh ln mt c" width="608" height="704" loading="lazy" role="presentation"/></picture></div></figure><h2 id="5781" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">2. Hybrid Retrieval + Memory Mechanisms</h2><p id="f9ee" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">LLMs can be augmented with <strong class="nu gv">memory mechanisms</strong> to maintain context across queries. Instead of breaking text into static chunks, the model recalls <strong class="nu gv">previous interactions</strong> and dynamically fetches relevant portions.</p><ul class=""><li id="6669" class="ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op pr ox oy bk"><strong class="nu gv">Memory-based retrieval</strong> improves conversational AI applications.</li><li id="0a47" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Hybrid methods</strong> mix traditional chunking with adaptive retrieval, <strong class="nu gv">reducing redundant token usage</strong>.</li></ul><h2 id="0bdf" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">3. Future Trends in Dynamic Chunking</h2><p id="87a4" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">The field of <strong class="nu gv">automated chunking</strong> is rapidly evolving, with new methods optimizing efficiency:</p><ul class=""><li id="e2a4" class="ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op pr ox oy bk"><strong class="nu gv">Context-Aware Chunking:</strong> Using AI to dynamically determine chunk sizes based on <strong class="nu gv">semantic importance</strong>.</li><li id="a062" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Transformer-Based Long-Context Models:</strong> Newer architectures (e.g., GPT-5, Claude) are being developed to <strong class="nu gv">handle longer context windows</strong>, reducing the need for chunking altogether.</li><li id="c9d4" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Hierarchical Processing:</strong> Instead of flat chunking, documents are broken down into a hierarchy, where high-level summaries lead to deeper insights <strong class="nu gv">only when necessary</strong>.</li></ul><figure class="qi qj qk ql qm mo mg mh paragraph-image"><div role="button" tabindex="0" class="mp mq fj mr bh ms"><div class="mg mh qr"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*h3-s4Eba2EijmiYjmgKSXg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*h3-s4Eba2EijmiYjmgKSXg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*h3-s4Eba2EijmiYjmgKSXg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*h3-s4Eba2EijmiYjmgKSXg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*h3-s4Eba2EijmiYjmgKSXg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*h3-s4Eba2EijmiYjmgKSXg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h3-s4Eba2EijmiYjmgKSXg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*h3-s4Eba2EijmiYjmgKSXg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*h3-s4Eba2EijmiYjmgKSXg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*h3-s4Eba2EijmiYjmgKSXg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*h3-s4Eba2EijmiYjmgKSXg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*h3-s4Eba2EijmiYjmgKSXg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*h3-s4Eba2EijmiYjmgKSXg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*h3-s4Eba2EijmiYjmgKSXg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bh ln mt c" width="700" height="653" loading="lazy" role="presentation"/></picture></div></div></figure><h1 id="78f1" class="mu mv gu bf mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr bk">What’s Next? (Present, Past, and Future)</h1><h2 id="761a" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">How Chunking Evolved from Traditional NLP Text Splitting</h2><p id="77bc" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">Before LLMs, <strong class="nu gv">NLP systems</strong> handled long documents using basic <strong class="nu gv">rule-based segmentation</strong>, such as paragraph or sentence-based splitting. With the rise of transformer models, <strong class="nu gv">more sophisticated chunking techniques</strong> became necessary.</p><h2 id="d28a" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">Where Chunking Stands Today in LLM Applications</h2><p id="b6a4" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">Today, chunking is a <strong class="nu gv">crucial preprocessing step</strong> for many AI applications, including:</p><ul class=""><li id="3efb" class="ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op pr ox oy bk"><strong class="nu gv">Legal AI</strong> for analyzing contracts.</li><li id="5adc" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Customer support chatbots</strong> retrieving FAQs.</li><li id="cd24" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Enterprise AI solutions</strong> processing massive datasets.</li></ul><h2 id="5d0d" class="ps mv gu bf mw pt pu dy na pv pw ea ne od px py pz oh qa qb qc ol qd qe qf qg bk">Future Improvements: Automated, Context-Aware Chunking Strategies</h2><p id="9d6c" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">Looking ahead, we anticipate:</p><ul class=""><li id="65b3" class="ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op pr ox oy bk"><strong class="nu gv">Reduced reliance on chunking</strong> with <strong class="nu gv">long-context transformers</strong>.</li><li id="cbce" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">AI-driven dynamic chunking</strong> optimizing retrieval strategies.</li><li id="6eb7" class="ns nt gu nu b nv oz nx ny nz pa ob oc od pb of og oh pc oj ok ol pd on oo op pr ox oy bk"><strong class="nu gv">Hybrid AI systems</strong> integrating <strong class="nu gv">memory, retrieval, and summarization</strong> techniques.</li></ul><h1 id="5c5d" class="mu mv gu bf mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr bk">Conclusion</h1><p id="0cec" class="pw-post-body-paragraph ns nt gu nu b nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op gn bk">Chunking remains an essential technique for handling <strong class="nu gv">large documents in LLMs</strong>, but new advancements in <strong class="nu gv">adaptive retrieval, memory mechanisms, and long-context models</strong> may eventually <strong class="nu gv">replace traditional chunking</strong>. As AI evolves, these innovations will lead to <strong class="nu gv">more efficient and cost-effective language model applications</strong>.</p><p id="8ee9" class="pw-post-body-paragraph ns nt gu nu b nv or nx ny nz os ob oc od ot of og oh ou oj ok ol ov on oo op gn bk">With these insights, developers can make <strong class="nu gv">informed choices</strong> about when to use chunking, when to explore alternatives, and how to optimize LLM efficiency for their specific use cases.</p></div></div></div></div></section></div></div></article></div><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="qs qt ab iv"><div class="qu ab"><a class="qv ay am ao" href="https://medium.com/tag/llm?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><div class="qw fj cx qx ge qy qz bf b bg z bk ra">Llm</div></a></div><div class="qu ab"><a class="qv ay am ao" href="https://medium.com/tag/machine-learning?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><div class="qw fj cx qx ge qy qz bf b bg z bk ra">Machine Learning</div></a></div><div class="qu ab"><a class="qv ay am ao" href="https://medium.com/tag/artificial-intelligence?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><div class="qw fj cx qx ge qy qz bf b bg z bk ra">Artificial Intelligence</div></a></div><div class="qu ab"><a class="qv ay am ao" href="https://medium.com/tag/nlp?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><div class="qw fj cx qx ge qy qz bf b bg z bk ra">NLP</div></a></div><div class="qu ab"><a class="qv ay am ao" href="https://medium.com/tag/large-language-models?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><div class="qw fj cx qx ge qy qz bf b bg z bk ra">Large Language Models</div></a></div></div></div></div><div class="l"></div><footer class="rb rc rd re rf ab q rg rh c"><div class="l ae"><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="ab cp ri"><div class="ab q ke"><div class="rj l"><span class="l rk rl rm e d"><div class="ab q ke kf"><div class="pw-multi-vote-icon fj kg kh ki kj"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F236dafe7b564&amp;operation=register&amp;redirect=https%3A%2F%2Fsushantgaurav57.medium.com%2Fllm-chunks-breaking-down-context-efficiently-236dafe7b564&amp;user=Sushant+Gaurav&amp;userId=41ed97b9bd38&amp;source=---footer_actions--236dafe7b564---------------------clap_footer------------------" rel="noopener follow"><div><div class="bm" aria-hidden="false"><div class="kk ao kl km kn ko am kp kq kr kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l ks kt ku kv kw kx ky"><p class="bf b dv z du"><span class="kz">--</span></p></div></div></span><span class="l h g f rn ro"><div class="ab q ke kf"><div class="pw-multi-vote-icon fj kg kh ki kj"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F236dafe7b564&amp;operation=register&amp;redirect=https%3A%2F%2Fsushantgaurav57.medium.com%2Fllm-chunks-breaking-down-context-efficiently-236dafe7b564&amp;user=Sushant+Gaurav&amp;userId=41ed97b9bd38&amp;source=---footer_actions--236dafe7b564---------------------clap_footer------------------" rel="noopener follow"><div><div class="bm" aria-hidden="false"><div class="kk ao kl km kn ko am kp kq kr kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l ks kt ku kv kw kx ky"><p class="bf b dv z du"><span class="kz">--</span></p></div></div></span></div><div class="bq ab"><div><div class="bm" aria-hidden="false"><button class="ao kk la lb ab q fk lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg></button></div></div></div></div><div class="ab q"><div class="pl l is"><div><div class="bm" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F236dafe7b564&amp;operation=register&amp;redirect=https%3A%2F%2Fsushantgaurav57.medium.com%2Fllm-chunks-breaking-down-context-efficiently-236dafe7b564&amp;source=---footer_actions--236dafe7b564---------------------bookmark_footer------------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du lg" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="pl l is"><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af fk ah ai aj ak al lo an ao ap ex lp lq ld lr"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="rp l"><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="ab rq rr rs iu it"><div class="rt ru rv rw rx ry rz sa sb sc ab cp"><div class="h k"><a tabindex="0" rel="noopener follow" href="/?source=post_page---post_author_info--236dafe7b564---------------------------------------"><div class="l fj"><img alt="Sushant Gaurav" class="l fd by ic ib cx" src="https://miro.medium.com/v2/resize:fill:96:96/1*zgHy2nSuAUuqTwQyuBS_FA.jpeg" width="48" height="48" loading="lazy"/><div class="fr by l ic ib fs n ay sd"></div></div></a></div><div class="j i d"><a tabindex="0" rel="noopener follow" href="/?source=post_page---post_author_info--236dafe7b564---------------------------------------"><div class="l fj"><img alt="Sushant Gaurav" class="l fd by se sf cx" src="https://miro.medium.com/v2/resize:fill:128:128/1*zgHy2nSuAUuqTwQyuBS_FA.jpeg" width="64" height="64" loading="lazy"/><div class="fr by l se sf fs n ay sd"></div></div></a></div><div class="j i d sg is"><div class="ab"><span><button class="bf b bg z sh qw si sj sk sl sm ev ew sn so sp fa fb fc fd bm fe ff">Follow</button></span></div></div></div><div class="ab co sq"><div class="sr ss st su sv l"><a class="af ag ah aj ak al am an ao ap aq ar as at ab q" rel="noopener follow" href="/?source=post_page---post_author_info--236dafe7b564---------------------------------------"><h2 class="pw-author-name bf sx sy sz ta tb tc td od py pz oh qb qc ol qe qf bk"><span class="gn sw">Written by <!-- -->Sushant Gaurav</span></h2></a><div class="qu ab ia"><div class="l is"><span class="pw-follower-count bf b bg z du"><a class="af ag ah ai aj ak al am an ao ap aq ar il" rel="noopener follow" href="/followers?source=post_page---post_author_info--236dafe7b564---------------------------------------">12 Followers</a></span></div><div class="bf b bg z du ab te"><span class="im l" aria-hidden="true"><span class="bf b bg z du">·</span></span><a class="af ag ah ai aj ak al am an ao ap aq ar il" rel="noopener follow" href="/following?source=post_page---post_author_info--236dafe7b564---------------------------------------">4 Following</a></div></div><div class="tf l"><p class="bf b bg z bk"><span class="gn">A pragmatic programmer 👨🏻‍💻 with a sarcastic mind 😉 who loves travelling and food :)</span></p></div></div></div><div class="h k"><div class="ab"><span><button class="bf b bg z sh qw si sj sk sl sm ev ew sn so sp fa fb fc fd bm fe ff">Follow</button></span></div></div></div></div></div></div><div class="tg l"><div class="th bh r rp"></div><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="ab q cp"><h2 class="bf sx mx mz na nb nd ne nf nh ni nj nl nm nn np nq bk">No responses yet</h2><div class="ab ti"><div><div class="bm" aria-hidden="false"><a class="tj tk" href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--236dafe7b564---------------------------------------" rel="noopener follow" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" viewBox="0 0 25 25"><path fill-rule="evenodd" d="M11.987 5.036a.754.754 0 0 1 .914-.01c.972.721 1.767 1.218 2.6 1.543.828.322 1.719.485 2.887.505a.755.755 0 0 1 .741.757c-.018 3.623-.43 6.256-1.449 8.21-1.034 1.984-2.662 3.209-4.966 4.083a.75.75 0 0 1-.537-.003c-2.243-.874-3.858-2.095-4.897-4.074-1.024-1.951-1.457-4.583-1.476-8.216a.755.755 0 0 1 .741-.757c1.195-.02 2.1-.182 2.923-.503.827-.322 1.6-.815 2.519-1.535m.468.903c-.897.69-1.717 1.21-2.623 1.564-.898.35-1.856.527-3.026.565.037 3.45.469 5.817 1.36 7.515.884 1.684 2.25 2.762 4.284 3.571 2.092-.81 3.465-1.89 4.344-3.575.886-1.698 1.299-4.065 1.334-7.512-1.149-.039-2.091-.217-2.99-.567-.906-.353-1.745-.873-2.683-1.561m-.009 9.155a2.672 2.672 0 1 0 0-5.344 2.672 2.672 0 0 0 0 5.344m0 1a3.672 3.672 0 1 0 0-7.344 3.672 3.672 0 0 0 0 7.344m-1.813-3.777.525-.526.916.917 1.623-1.625.526.526-2.149 2.152z" clip-rule="evenodd"></path></svg></a></div></div></div></div><div class="tl tm tn to tp l"></div></div></div></div><div class="tq tr ts tt tu l bx"><div class="h k j"><div class="th bh tv tw"></div><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="tx ab ke iv"><div class="ty tz l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><p class="bf b dv z du">Help</p></a></div><div class="ty tz l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><p class="bf b dv z du">Status</p></a></div><div class="ty tz l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/about?autoplay=1&amp;source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><p class="bf b dv z du">About</p></a></div><div class="ty tz l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><p class="bf b dv z du">Careers</p></a></div><div class="ty tz l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="mailto:pressinquiries@medium.com" rel="noopener follow"><p class="bf b dv z du">Press</p></a></div><div class="ty tz l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><p class="bf b dv z du">Blog</p></a></div><div class="ty tz l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><p class="bf b dv z du">Privacy</p></a></div><div class="ty tz l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><p class="bf b dv z du">Terms</p></a></div><div class="ty tz l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><p class="bf b dv z du">Text to speech</p></a></div><div class="ty l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/business?source=post_page-----236dafe7b564---------------------------------------" rel="noopener follow"><p class="bf b dv z du">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20250310-154226-e5355abb17"</script><script>window.__GRAPHQL_URI__ = "https://sushantgaurav57.medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-236dafe7b564","user-41ed97b9bd38"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[],"pubFeaturingPostPageLabelEnabled":false,"pubHierarchyFlagGroup":"control"},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"USER","id":"41ed97b9bd38","explicit":true},"viewerIsBot":false},"debug":{"requestId":"6f5bc5e3-2630-4228-a78c-470326dfd36d","requestTag":"","hybridDevServices":[],"originalSpanCarrier":{"traceparent":"00-e1b15e2ab8ded5521fc63b03b72c629d-cac2a030433eb99b-01"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fsushantgaurav57.medium.com\u002Fllm-chunks-breaking-down-context-efficiently-236dafe7b564","host":"sushantgaurav57.medium.com","hostname":"sushantgaurav57.medium.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"partnerProgram":{"selectedCountryCode":null},"queryString":"","currentHash":""},"config":{"nodeEnv":"production","version":"main-20250310-154226-e5355abb17","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20250310-154226-e5355abb17","commit":"e5355abb17fb648e66bf0c649ed688b908e8205e"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"7*V1_7XP4snlmqrc_0Njontw.png","height":110,"width":500},"postLogo":{"imageId":"bd978bb536350a710e8efb012513429cabdc4c28700604261aeda246d0f980b7","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyV2":"e8a5e126-792b-4ee6-8fba-d574c1b02fc5","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyV2":"3815d7d6-b8ca-4224-9b8c-182f9047866e","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyOneYearFree":"e6c0637a-2bad-4171-ab4f-3c268633d83c","monthly25PercentOffFirstYear":"235ecc62-0cdb-49ae-9378-726cd21c504b","monthly20PercentOffFirstYear":"ba518864-9c13-4a99-91ca-411bf0cac756","monthly15PercentOffFirstYear":"594c029b-9f89-43d5-88f8-8173af4e070e","monthly10PercentOffFirstYear":"c6c7bc9a-40f2-4b51-8126-e28511d5bdb0","monthlyForStudents":"629ebe51-da7d-41fd-8293-34cd2f2030a8","yearlyOneYearFree":"78ba7be9-0d9f-4ece-aa3e-b54b826f2bf1","yearly25PercentOffFirstYear":"2dbb010d-bb8f-4eeb-ad5c-a08509f42d34","yearly20PercentOffFirstYear":"47565488-435b-47f8-bf93-40d5fbe0ebc8","yearly15PercentOffFirstYear":"8259809b-0881-47d9-acf7-6c001c7f720f","yearly10PercentOffFirstYear":"9dd694fb-96e1-472c-8d9e-3c868d5c1506","yearlyForStudents":"e29345ef-ab1c-4234-95c5-70e50fe6bc23","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"collectionByDomainOrSlug({\"domainOrSlug\":\"sushantgaurav57.medium.com\"})":null,"postResult({\"id\":\"236dafe7b564\"})":{"__ref":"Post:236dafe7b564"}},"LinkedAccounts:41ed97b9bd38":{"__typename":"LinkedAccounts","mastodon":null,"id":"41ed97b9bd38"},"User:41ed97b9bd38":{"__typename":"User","id":"41ed97b9bd38","linkedAccounts":{"__ref":"LinkedAccounts:41ed97b9bd38"},"isSuspended":false,"name":"Sushant Gaurav","imageId":"1*zgHy2nSuAUuqTwQyuBS_FA.jpeg","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"sushantgaurav57.medium.com"}},"hasSubdomain":true,"username":"sushantgaurav57","verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":12,"followingCount":2,"collectionFollowingCount":2},"bio":"A pragmatic programmer 👨🏻‍💻 with a sarcastic mind 😉 who loves travelling and food :)","membership":null,"allowNotes":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:41ed97b9bd38-viewerId:lo_b9d881412f94"},"twitterScreenName":""},"Paragraph:a46eb223feca_0":{"__typename":"Paragraph","id":"a46eb223feca_0","name":"d924","type":"H3","href":null,"layout":null,"metadata":null,"text":"LLM Chunks — Breaking Down Context Efficiently","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*ln16vamAkf_WoiyAQjSL6w.png":{"__typename":"ImageMetadata","id":"1*ln16vamAkf_WoiyAQjSL6w.png","originalHeight":742,"originalWidth":1308,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a46eb223feca_1":{"__typename":"Paragraph","id":"a46eb223feca_1","name":"6cc9","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*ln16vamAkf_WoiyAQjSL6w.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_2":{"__typename":"Paragraph","id":"a46eb223feca_2","name":"9d94","type":"H3","href":null,"layout":null,"metadata":null,"text":"Series Overview","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_3":{"__typename":"Paragraph","id":"a46eb223feca_3","name":"1a63","type":"P","href":null,"layout":null,"metadata":null,"text":"So far, we have explored the evolution of Machine Learning (ML) and Natural Language Processing (NLP), leading up to modern Transformer-based models like GPT, BERT, and LLaMA. We have also dived into Vector Search, Embeddings, and Retrieval-Augmented Generation (RAG) systems, understanding how they enhance Large Language Models (LLMs). Additionally, we have simplified Vector Databases, explaining their fundamentals and real-world applications. Lastly, we have covered LangChain, its role in orchestrating LLM applications, and its practical implementations.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":42,"end":102,"href":"https:\u002F\u002Fmedium.com\u002Fp\u002F4a64a679011b","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":200,"end":267,"href":"https:\u002F\u002Fmedium.com\u002Fp\u002Fea45fe63d89a","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":371,"end":387,"href":"https:\u002F\u002Fmedium.com\u002Fp\u002F18b1ce9e1a4b","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":472,"end":481,"href":"https:\u002F\u002Fmedium.com\u002Fp\u002F1e80585402e3","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":42,"end":101,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":124,"end":148,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":154,"end":174,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":200,"end":267,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":308,"end":336,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":371,"end":387,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":472,"end":481,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_4":{"__typename":"Paragraph","id":"a46eb223feca_4","name":"afaf","type":"P","href":null,"layout":null,"metadata":null,"text":"Building on this foundation, we now move forward with two key aspects of LLMs:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_5":{"__typename":"Paragraph","id":"a46eb223feca_5","name":"cc3c","type":"OLI","href":null,"layout":null,"metadata":null,"text":"How chunking works in LLMs and its impact on cost and efficiency","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":64,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_6":{"__typename":"Paragraph","id":"a46eb223feca_6","name":"aa39","type":"OLI","href":null,"layout":null,"metadata":null,"text":"The broader impact of LLMs on ML, AI, and various industries","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":60,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_7":{"__typename":"Paragraph","id":"a46eb223feca_7","name":"fbbf","type":"H3","href":null,"layout":null,"metadata":null,"text":"LLM Chunks — Breaking Down Context Efficiently","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_8":{"__typename":"Paragraph","id":"a46eb223feca_8","name":"8bac","type":"P","href":null,"layout":null,"metadata":null,"text":"To effectively process long documents, LLMs break text into chunks before passing it as input. Choosing the right chunking method is critical because it affects context retention, accuracy, latency, and cost. In this article, we explore different chunking strategies, their trade-offs, and possible alternatives to improve efficiency.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":44,"end":66,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":161,"end":207,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":247,"end":266,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_9":{"__typename":"Paragraph","id":"a46eb223feca_9","name":"f9c9","type":"H3","href":null,"layout":null,"metadata":null,"text":"What is Chunking in LLMs?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_10":{"__typename":"Paragraph","id":"a46eb223feca_10","name":"9cd1","type":"P","href":null,"layout":null,"metadata":null,"text":"Chunking in the context of LLMs refers to the process of dividing large text documents into smaller, manageable segments (chunks) before feeding them into the model. Since LLMs have a fixed context window, they cannot process infinite-length documents directly.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":46,"end":129,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":184,"end":204,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_11":{"__typename":"Paragraph","id":"a46eb223feca_11","name":"137b","type":"H3","href":null,"layout":null,"metadata":null,"text":"Why LLMs Need Chunking?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_12":{"__typename":"Paragraph","id":"a46eb223feca_12","name":"413f","type":"P","href":null,"layout":null,"metadata":null,"text":"LLMs like GPT-4 and BERT have token limits (e.g., GPT-4’s context window is 8K-32K tokens). If a document exceeds this limit, it must be split into smaller sections. Chunking ensures that:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":10,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":20,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_13":{"__typename":"Paragraph","id":"a46eb223feca_13","name":"6600","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LLMs don’t miss critical information when handling large documents.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":36,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_14":{"__typename":"Paragraph","id":"a46eb223feca_14","name":"e351","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Queries retrieve relevant sections efficiently instead of processing an entire dataset.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":46,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_15":{"__typename":"Paragraph","id":"a46eb223feca_15","name":"afe7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Costs are optimized by reducing unnecessary token usage.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_16":{"__typename":"Paragraph","id":"a46eb223feca_16","name":"1950","type":"H3","href":null,"layout":null,"metadata":null,"text":"Real-World Use Cases Where Chunking is Essential","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_17":{"__typename":"Paragraph","id":"a46eb223feca_17","name":"4d4e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Legal Document Analysis: Long contracts are split into sections for summarization.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_18":{"__typename":"Paragraph","id":"a46eb223feca_18","name":"00b5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Customer Support AI: Splitting FAQ databases into smaller knowledge chunks.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_19":{"__typename":"Paragraph","id":"a46eb223feca_19","name":"eeeb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Academic Research: Processing multi-page research papers efficiently.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_20":{"__typename":"Paragraph","id":"a46eb223feca_20","name":"2deb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Medical Records Analysis: Breaking down patient history for diagnostics.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_21":{"__typename":"Paragraph","id":"a46eb223feca_21","name":"086e","type":"H3","href":null,"layout":null,"metadata":null,"text":"Common Chunking Methods","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_22":{"__typename":"Paragraph","id":"a46eb223feca_22","name":"f1b6","type":"H4","href":null,"layout":null,"metadata":null,"text":"1. Stuffing Method","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_23":{"__typename":"Paragraph","id":"a46eb223feca_23","name":"d86b","type":"P","href":null,"layout":null,"metadata":null,"text":"In this method, all text is stuffed into a single chunk until the model’s token limit is reached. While simple, it has downsides:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_24":{"__typename":"Paragraph","id":"a46eb223feca_24","name":"8adf","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Pros: Low latency, easy to implement.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_25":{"__typename":"Paragraph","id":"a46eb223feca_25","name":"733b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Cons: Risk of losing information from truncated sections.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*zfNJBtPFAhab0Xs9J7GAmQ.png":{"__typename":"ImageMetadata","id":"1*zfNJBtPFAhab0Xs9J7GAmQ.png","originalHeight":690,"originalWidth":426,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a46eb223feca_26":{"__typename":"Paragraph","id":"a46eb223feca_26","name":"ce3a","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*zfNJBtPFAhab0Xs9J7GAmQ.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_27":{"__typename":"Paragraph","id":"a46eb223feca_27","name":"60e1","type":"H4","href":null,"layout":null,"metadata":null,"text":"2. Map-Reduce Method","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_28":{"__typename":"Paragraph","id":"a46eb223feca_28","name":"fe63","type":"P","href":null,"layout":null,"metadata":null,"text":"This method splits the document into multiple chunks, processes each one separately, and then combines results.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":12,"end":52,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_29":{"__typename":"Paragraph","id":"a46eb223feca_29","name":"b1fd","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Pros: Scales well for large texts.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_30":{"__typename":"Paragraph","id":"a46eb223feca_30","name":"fe30","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Cons: The combined result may lose coherence.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*N9ema5QK88Um2W2HBiBihA.png":{"__typename":"ImageMetadata","id":"1*N9ema5QK88Um2W2HBiBihA.png","originalHeight":716,"originalWidth":804,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a46eb223feca_31":{"__typename":"Paragraph","id":"a46eb223feca_31","name":"c874","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*N9ema5QK88Um2W2HBiBihA.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_32":{"__typename":"Paragraph","id":"a46eb223feca_32","name":"abf3","type":"H4","href":null,"layout":null,"metadata":null,"text":"3. Recursive Summary Method","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_33":{"__typename":"Paragraph","id":"a46eb223feca_33","name":"abdc","type":"P","href":null,"layout":null,"metadata":null,"text":"This method involves summarizing individual chunks first, and then summarizing those summaries, ensuring context retention.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":21,"end":56,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_34":{"__typename":"Paragraph","id":"a46eb223feca_34","name":"4034","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Pros: Retains more relevant context.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_35":{"__typename":"Paragraph","id":"a46eb223feca_35","name":"ec20","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Cons: Requires multiple processing passes, increasing cost.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_36":{"__typename":"Paragraph","id":"a46eb223feca_36","name":"c947","type":"H4","href":null,"layout":null,"metadata":null,"text":"4. Embedding-Based Chunking","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_37":{"__typename":"Paragraph","id":"a46eb223feca_37","name":"2986","type":"P","href":null,"layout":null,"metadata":null,"text":"Instead of breaking text at arbitrary points, this method uses semantic similarity to keep related information together. This is useful in vector databases and RAG.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":63,"end":82,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":139,"end":163,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_38":{"__typename":"Paragraph","id":"a46eb223feca_38","name":"0231","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Pros: Ensures chunks retain full meaning.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_39":{"__typename":"Paragraph","id":"a46eb223feca_39","name":"59d2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Cons: Requires extra computation to determine chunk boundaries.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*UaCOkXK227_6V_kC3Tl-QQ.png":{"__typename":"ImageMetadata","id":"1*UaCOkXK227_6V_kC3Tl-QQ.png","originalHeight":716,"originalWidth":550,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a46eb223feca_40":{"__typename":"Paragraph","id":"a46eb223feca_40","name":"82e7","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*UaCOkXK227_6V_kC3Tl-QQ.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_41":{"__typename":"Paragraph","id":"a46eb223feca_41","name":"bd47","type":"H3","href":null,"layout":null,"metadata":null,"text":"The Cost and Performance Trade-offs of Chunking","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_42":{"__typename":"Paragraph","id":"a46eb223feca_42","name":"231b","type":"H4","href":null,"layout":null,"metadata":null,"text":"Impact on API Call Costs","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_43":{"__typename":"Paragraph","id":"a46eb223feca_43","name":"f712","type":"P","href":null,"layout":null,"metadata":null,"text":"Chunking affects the cost of LLM API calls, as providers charge based on token usage. Choosing the right chunking method can significantly optimize expenses.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":29,"end":42,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":73,"end":84,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_44":{"__typename":"Paragraph","id":"a46eb223feca_44","name":"e572","type":"P","href":null,"layout":null,"metadata":null,"text":"Chunking Method Token Usage Accuracy Cost Stuffing High Moderate Expensive Map-Reduce Medium High Moderate Recursive Summary Low High Expensive Embedding-Based Medium Very High Moderate","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_45":{"__typename":"Paragraph","id":"a46eb223feca_45","name":"9cdc","type":"H4","href":null,"layout":null,"metadata":null,"text":"Accuracy vs. Speed vs. Computational Expense","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_46":{"__typename":"Paragraph","id":"a46eb223feca_46","name":"ff59","type":"ULI","href":null,"layout":null,"metadata":null,"text":"More chunks = Better retrieval accuracy, but higher cost.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":57,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_47":{"__typename":"Paragraph","id":"a46eb223feca_47","name":"4745","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Fewer chunks = Lower cost, but higher risk of missing context.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":62,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_48":{"__typename":"Paragraph","id":"a46eb223feca_48","name":"759e","type":"H4","href":null,"layout":null,"metadata":null,"text":"Problems with Excessive Chunking","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_49":{"__typename":"Paragraph","id":"a46eb223feca_49","name":"c31b","type":"P","href":null,"layout":null,"metadata":null,"text":"Too many small chunks can cause:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_50":{"__typename":"Paragraph","id":"a46eb223feca_50","name":"ae90","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Loss of coherence (context gets fragmented across multiple chunks).","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_51":{"__typename":"Paragraph","id":"a46eb223feca_51","name":"8690","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Higher processing costs due to increased API calls.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*AjYFxDpmjudrC1AwGDjo2w.png":{"__typename":"ImageMetadata","id":"1*AjYFxDpmjudrC1AwGDjo2w.png","originalHeight":172,"originalWidth":1062,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a46eb223feca_52":{"__typename":"Paragraph","id":"a46eb223feca_52","name":"8038","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*AjYFxDpmjudrC1AwGDjo2w.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_53":{"__typename":"Paragraph","id":"a46eb223feca_53","name":"5feb","type":"H3","href":null,"layout":null,"metadata":null,"text":"Is There a Better Alternative to Chunking?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_54":{"__typename":"Paragraph","id":"a46eb223feca_54","name":"c666","type":"P","href":null,"layout":null,"metadata":null,"text":"While chunking is a practical way to handle LLM token limits, alternative methods aim to reduce chunking overhead while improving accuracy and efficiency. Some promising alternatives include:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":89,"end":113,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_55":{"__typename":"Paragraph","id":"a46eb223feca_55","name":"82bb","type":"H4","href":null,"layout":null,"metadata":null,"text":"1. Adaptive Retrieval Techniques","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_56":{"__typename":"Paragraph","id":"a46eb223feca_56","name":"f8b1","type":"P","href":null,"layout":null,"metadata":null,"text":"Instead of blindly chunking text, adaptive retrieval dynamically retrieves the most relevant sections based on the query. This is particularly useful in Retrieval-Augmented Generation (RAG) systems.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":34,"end":52,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":153,"end":197,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_57":{"__typename":"Paragraph","id":"a46eb223feca_57","name":"60eb","type":"H4","href":null,"layout":null,"metadata":null,"text":"How Adaptive Retrieval Works:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":29,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_58":{"__typename":"Paragraph","id":"a46eb223feca_58","name":"41c7","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Convert the document into vector embeddings.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":26,"end":43,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_59":{"__typename":"Paragraph","id":"a46eb223feca_59","name":"7600","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Store embeddings in a vector database.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":22,"end":37,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_60":{"__typename":"Paragraph","id":"a46eb223feca_60","name":"bf5d","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Retrieve the most relevant passages based on semantic similarity instead of fixed chunk sizes.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":45,"end":64,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_61":{"__typename":"Paragraph","id":"a46eb223feca_61","name":"6ad0","type":"P","href":null,"layout":null,"metadata":null,"text":"Example Workflow:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*poDsykkLGaD8X6BJANHpWA.png":{"__typename":"ImageMetadata","id":"1*poDsykkLGaD8X6BJANHpWA.png","originalHeight":704,"originalWidth":608,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a46eb223feca_62":{"__typename":"Paragraph","id":"a46eb223feca_62","name":"39db","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*poDsykkLGaD8X6BJANHpWA.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_63":{"__typename":"Paragraph","id":"a46eb223feca_63","name":"5781","type":"H4","href":null,"layout":null,"metadata":null,"text":"2. Hybrid Retrieval + Memory Mechanisms","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_64":{"__typename":"Paragraph","id":"a46eb223feca_64","name":"f9ee","type":"P","href":null,"layout":null,"metadata":null,"text":"LLMs can be augmented with memory mechanisms to maintain context across queries. Instead of breaking text into static chunks, the model recalls previous interactions and dynamically fetches relevant portions.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":27,"end":44,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":144,"end":165,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_65":{"__typename":"Paragraph","id":"a46eb223feca_65","name":"6669","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Memory-based retrieval improves conversational AI applications.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_66":{"__typename":"Paragraph","id":"a46eb223feca_66","name":"0a47","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Hybrid methods mix traditional chunking with adaptive retrieval, reducing redundant token usage.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":14,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":65,"end":95,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_67":{"__typename":"Paragraph","id":"a46eb223feca_67","name":"0bdf","type":"H4","href":null,"layout":null,"metadata":null,"text":"3. Future Trends in Dynamic Chunking","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_68":{"__typename":"Paragraph","id":"a46eb223feca_68","name":"87a4","type":"P","href":null,"layout":null,"metadata":null,"text":"The field of automated chunking is rapidly evolving, with new methods optimizing efficiency:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":13,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_69":{"__typename":"Paragraph","id":"a46eb223feca_69","name":"e2a4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Context-Aware Chunking: Using AI to dynamically determine chunk sizes based on semantic importance.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":79,"end":98,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_70":{"__typename":"Paragraph","id":"a46eb223feca_70","name":"a062","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Transformer-Based Long-Context Models: Newer architectures (e.g., GPT-5, Claude) are being developed to handle longer context windows, reducing the need for chunking altogether.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":38,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":104,"end":133,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_71":{"__typename":"Paragraph","id":"a46eb223feca_71","name":"c9d4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Hierarchical Processing: Instead of flat chunking, documents are broken down into a hierarchy, where high-level summaries lead to deeper insights only when necessary.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":146,"end":165,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*h3-s4Eba2EijmiYjmgKSXg.png":{"__typename":"ImageMetadata","id":"1*h3-s4Eba2EijmiYjmgKSXg.png","originalHeight":712,"originalWidth":764,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a46eb223feca_72":{"__typename":"Paragraph","id":"a46eb223feca_72","name":"afb2","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*h3-s4Eba2EijmiYjmgKSXg.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_73":{"__typename":"Paragraph","id":"a46eb223feca_73","name":"78f1","type":"H3","href":null,"layout":null,"metadata":null,"text":"What’s Next? (Present, Past, and Future)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_74":{"__typename":"Paragraph","id":"a46eb223feca_74","name":"761a","type":"H4","href":null,"layout":null,"metadata":null,"text":"How Chunking Evolved from Traditional NLP Text Splitting","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_75":{"__typename":"Paragraph","id":"a46eb223feca_75","name":"77bc","type":"P","href":null,"layout":null,"metadata":null,"text":"Before LLMs, NLP systems handled long documents using basic rule-based segmentation, such as paragraph or sentence-based splitting. With the rise of transformer models, more sophisticated chunking techniques became necessary.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":13,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":60,"end":83,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":169,"end":207,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_76":{"__typename":"Paragraph","id":"a46eb223feca_76","name":"d28a","type":"H4","href":null,"layout":null,"metadata":null,"text":"Where Chunking Stands Today in LLM Applications","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_77":{"__typename":"Paragraph","id":"a46eb223feca_77","name":"b6a4","type":"P","href":null,"layout":null,"metadata":null,"text":"Today, chunking is a crucial preprocessing step for many AI applications, including:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":21,"end":47,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_78":{"__typename":"Paragraph","id":"a46eb223feca_78","name":"3efb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Legal AI for analyzing contracts.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":8,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_79":{"__typename":"Paragraph","id":"a46eb223feca_79","name":"5adc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Customer support chatbots retrieving FAQs.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":25,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_80":{"__typename":"Paragraph","id":"a46eb223feca_80","name":"cd24","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Enterprise AI solutions processing massive datasets.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_81":{"__typename":"Paragraph","id":"a46eb223feca_81","name":"5d0d","type":"H4","href":null,"layout":null,"metadata":null,"text":"Future Improvements: Automated, Context-Aware Chunking Strategies","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_82":{"__typename":"Paragraph","id":"a46eb223feca_82","name":"9d6c","type":"P","href":null,"layout":null,"metadata":null,"text":"Looking ahead, we anticipate:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_83":{"__typename":"Paragraph","id":"a46eb223feca_83","name":"65b3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Reduced reliance on chunking with long-context transformers.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":28,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":34,"end":59,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_84":{"__typename":"Paragraph","id":"a46eb223feca_84","name":"cbce","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AI-driven dynamic chunking optimizing retrieval strategies.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":26,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_85":{"__typename":"Paragraph","id":"a46eb223feca_85","name":"6eb7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Hybrid AI systems integrating memory, retrieval, and summarization techniques.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":30,"end":66,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_86":{"__typename":"Paragraph","id":"a46eb223feca_86","name":"5c5d","type":"H3","href":null,"layout":null,"metadata":null,"text":"Conclusion","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_87":{"__typename":"Paragraph","id":"a46eb223feca_87","name":"0cec","type":"P","href":null,"layout":null,"metadata":null,"text":"Chunking remains an essential technique for handling large documents in LLMs, but new advancements in adaptive retrieval, memory mechanisms, and long-context models may eventually replace traditional chunking. As AI evolves, these innovations will lead to more efficient and cost-effective language model applications.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":53,"end":76,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":102,"end":164,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":180,"end":208,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":256,"end":317,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a46eb223feca_88":{"__typename":"Paragraph","id":"a46eb223feca_88","name":"8ee9","type":"P","href":null,"layout":null,"metadata":null,"text":"With these insights, developers can make informed choices about when to use chunking, when to explore alternatives, and how to optimize LLM efficiency for their specific use cases.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":41,"end":57,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"UserViewerEdge:userId:41ed97b9bd38-viewerId:lo_b9d881412f94":{"__typename":"UserViewerEdge","id":"userId:41ed97b9bd38-viewerId:lo_b9d881412f94","isMuting":false},"PostViewerEdge:postId:236dafe7b564-viewerId:lo_b9d881412f94":{"__typename":"PostViewerEdge","shouldIndexPostForExternalSearch":true,"id":"postId:236dafe7b564-viewerId:lo_b9d881412f94"},"Tag:llm":{"__typename":"Tag","id":"llm","displayTitle":"Llm","normalizedTagSlug":"llm"},"Tag:machine-learning":{"__typename":"Tag","id":"machine-learning","displayTitle":"Machine Learning","normalizedTagSlug":"machine-learning"},"Tag:artificial-intelligence":{"__typename":"Tag","id":"artificial-intelligence","displayTitle":"Artificial Intelligence","normalizedTagSlug":"artificial-intelligence"},"Tag:nlp":{"__typename":"Tag","id":"nlp","displayTitle":"NLP","normalizedTagSlug":"nlp"},"Tag:large-language-models":{"__typename":"Tag","id":"large-language-models","displayTitle":"Large Language Models","normalizedTagSlug":"large-language-models"},"Post:236dafe7b564":{"__typename":"Post","id":"236dafe7b564","collection":null,"content({\"postMeteringOptions\":{\"referrer\":\"\"}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"4471","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"e3db","startIndex":7,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:a46eb223feca_0"},{"__ref":"Paragraph:a46eb223feca_1"},{"__ref":"Paragraph:a46eb223feca_2"},{"__ref":"Paragraph:a46eb223feca_3"},{"__ref":"Paragraph:a46eb223feca_4"},{"__ref":"Paragraph:a46eb223feca_5"},{"__ref":"Paragraph:a46eb223feca_6"},{"__ref":"Paragraph:a46eb223feca_7"},{"__ref":"Paragraph:a46eb223feca_8"},{"__ref":"Paragraph:a46eb223feca_9"},{"__ref":"Paragraph:a46eb223feca_10"},{"__ref":"Paragraph:a46eb223feca_11"},{"__ref":"Paragraph:a46eb223feca_12"},{"__ref":"Paragraph:a46eb223feca_13"},{"__ref":"Paragraph:a46eb223feca_14"},{"__ref":"Paragraph:a46eb223feca_15"},{"__ref":"Paragraph:a46eb223feca_16"},{"__ref":"Paragraph:a46eb223feca_17"},{"__ref":"Paragraph:a46eb223feca_18"},{"__ref":"Paragraph:a46eb223feca_19"},{"__ref":"Paragraph:a46eb223feca_20"},{"__ref":"Paragraph:a46eb223feca_21"},{"__ref":"Paragraph:a46eb223feca_22"},{"__ref":"Paragraph:a46eb223feca_23"},{"__ref":"Paragraph:a46eb223feca_24"},{"__ref":"Paragraph:a46eb223feca_25"},{"__ref":"Paragraph:a46eb223feca_26"},{"__ref":"Paragraph:a46eb223feca_27"},{"__ref":"Paragraph:a46eb223feca_28"},{"__ref":"Paragraph:a46eb223feca_29"},{"__ref":"Paragraph:a46eb223feca_30"},{"__ref":"Paragraph:a46eb223feca_31"},{"__ref":"Paragraph:a46eb223feca_32"},{"__ref":"Paragraph:a46eb223feca_33"},{"__ref":"Paragraph:a46eb223feca_34"},{"__ref":"Paragraph:a46eb223feca_35"},{"__ref":"Paragraph:a46eb223feca_36"},{"__ref":"Paragraph:a46eb223feca_37"},{"__ref":"Paragraph:a46eb223feca_38"},{"__ref":"Paragraph:a46eb223feca_39"},{"__ref":"Paragraph:a46eb223feca_40"},{"__ref":"Paragraph:a46eb223feca_41"},{"__ref":"Paragraph:a46eb223feca_42"},{"__ref":"Paragraph:a46eb223feca_43"},{"__ref":"Paragraph:a46eb223feca_44"},{"__ref":"Paragraph:a46eb223feca_45"},{"__ref":"Paragraph:a46eb223feca_46"},{"__ref":"Paragraph:a46eb223feca_47"},{"__ref":"Paragraph:a46eb223feca_48"},{"__ref":"Paragraph:a46eb223feca_49"},{"__ref":"Paragraph:a46eb223feca_50"},{"__ref":"Paragraph:a46eb223feca_51"},{"__ref":"Paragraph:a46eb223feca_52"},{"__ref":"Paragraph:a46eb223feca_53"},{"__ref":"Paragraph:a46eb223feca_54"},{"__ref":"Paragraph:a46eb223feca_55"},{"__ref":"Paragraph:a46eb223feca_56"},{"__ref":"Paragraph:a46eb223feca_57"},{"__ref":"Paragraph:a46eb223feca_58"},{"__ref":"Paragraph:a46eb223feca_59"},{"__ref":"Paragraph:a46eb223feca_60"},{"__ref":"Paragraph:a46eb223feca_61"},{"__ref":"Paragraph:a46eb223feca_62"},{"__ref":"Paragraph:a46eb223feca_63"},{"__ref":"Paragraph:a46eb223feca_64"},{"__ref":"Paragraph:a46eb223feca_65"},{"__ref":"Paragraph:a46eb223feca_66"},{"__ref":"Paragraph:a46eb223feca_67"},{"__ref":"Paragraph:a46eb223feca_68"},{"__ref":"Paragraph:a46eb223feca_69"},{"__ref":"Paragraph:a46eb223feca_70"},{"__ref":"Paragraph:a46eb223feca_71"},{"__ref":"Paragraph:a46eb223feca_72"},{"__ref":"Paragraph:a46eb223feca_73"},{"__ref":"Paragraph:a46eb223feca_74"},{"__ref":"Paragraph:a46eb223feca_75"},{"__ref":"Paragraph:a46eb223feca_76"},{"__ref":"Paragraph:a46eb223feca_77"},{"__ref":"Paragraph:a46eb223feca_78"},{"__ref":"Paragraph:a46eb223feca_79"},{"__ref":"Paragraph:a46eb223feca_80"},{"__ref":"Paragraph:a46eb223feca_81"},{"__ref":"Paragraph:a46eb223feca_82"},{"__ref":"Paragraph:a46eb223feca_83"},{"__ref":"Paragraph:a46eb223feca_84"},{"__ref":"Paragraph:a46eb223feca_85"},{"__ref":"Paragraph:a46eb223feca_86"},{"__ref":"Paragraph:a46eb223feca_87"},{"__ref":"Paragraph:a46eb223feca_88"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:41ed97b9bd38"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Fsushantgaurav57.medium.com\u002Fllm-chunks-breaking-down-context-efficiently-236dafe7b564","primaryTopic":null,"topics":[{"__typename":"Topic","slug":"machine-learning"},{"__typename":"Topic","slug":"data-science"},{"__typename":"Topic","slug":"programming"}],"isLimitedState":false,"isPublished":true,"allowResponses":true,"responsesLocked":false,"visibility":"PUBLIC","latestPublishedVersion":"a46eb223feca","postResponses":{"__typename":"PostResponses","count":0},"responseDistribution":"NOT_DISTRIBUTED","clapCount":0,"title":"LLM Chunks — Breaking Down Context Efficiently","isSeries":false,"sequence":null,"uniqueSlug":"llm-chunks-breaking-down-context-efficiently-236dafe7b564","socialTitle":"","socialDek":"","canonicalUrl":"","metaDescription":"","latestPublishedAt":1740553561254,"readingTime":4.910377358490566,"previewContent":{"__typename":"PreviewContent","subtitle":"Series Overview"},"previewImage":{"__ref":"ImageMetadata:1*ln16vamAkf_WoiyAQjSL6w.png"},"isShortform":false,"seoTitle":"","firstPublishedAt":1740553561254,"updatedAt":1740558547531,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","viewerEdge":{"__ref":"PostViewerEdge:postId:236dafe7b564-viewerId:lo_b9d881412f94"},"isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:llm"},{"__ref":"Tag:machine-learning"},{"__ref":"Tag:artificial-intelligence"},{"__ref":"Tag:nlp"},{"__ref":"Tag:large-language-models"}],"isFeaturedInPublishedPublication":false,"isNewsletter":false,"statusForCollection":null,"pendingCollection":null,"detectedLanguage":"en","wordCount":1023,"layerCake":0}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":""},"cache":{"cacheStatus":"MISS"}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.36afbc93.js"></script><script src="https://cdn-client.medium.com/lite/static/js/9865.1496d74a.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.f6fb3e59.js"></script><script src="https://cdn-client.medium.com/lite/static/js/instrumentation.5bef8967.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.ff22a7a5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5049.d1ead72d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4505.6dfaf853.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6618.db187378.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9380.fb176dee.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2707.2278ed76.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9977.933c1c9a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8599.2418028f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3045.1cc3d8cb.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6349.3329b100.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2648.26563adf.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8393.67b7130d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6428.1164cc97.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6199.c727247b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5642.472363b5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6546.bb55b1c9.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6834.8aa8d357.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2107.a45f417e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2571.6814b962.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/839.1c286b32.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6128.f8800a13.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2135.6ef5c5cf.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7975.60bcefe8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/144.261fc28c.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5240.6281357f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8819.c627c2bf.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8204.2636b118.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1201.8abafe50.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.5a847cd7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8414.0d800846.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3974.8d3e0217.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2527.b9f95853.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostResponsesContent.8fccab9f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/responses.editor.33e18640.chunk.js"></script><script>window.main();</script></body></html>